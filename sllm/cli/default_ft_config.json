{
    "model": "",
    "ft_backend": "peft",
    "ft_backend_config": {
        "pretrained_model_name_or_path": "bigscience/bloomz-560m",
        "device_map": "auto",
        "torch_dtype": "float16",
        "hf_model_class": "AutoModelForCausalLM"
    },
    "epochs": 2,
    "batch_size": 32,
    "learning_rate": 0.0001,
    "dataset": "",
    "lora_config": {
        "r": 4,
        "lora_alpha": 1,
        "target_modules": ["query_key_value"],
        "lora_dropout": 0.05,
        "bias": "lora_only",
        "task_type": "CAUSAL_LM"
    }
}