{
    "model": "bigscience/bloomz-560m",
    "ft_backend": "peft",
    "training_config": {
        "auto_find_batch_size": "True",
        "num_train_epochs": 2,
        "learning_rate": 0.0001,
        "optim": "",
        "use_cpu": "False"
    },
    "dataset_config": {
        "dataset_source": "hf_hub",
        "hf_dataset_name": "fka/awesome-chatgpt-prompts",
        "tokenization_field": "prompt",
        "split": "train",
        "data_files": "",
        "extension_type": ""
    },
    "lora_config": {
        "r": 4,
        "lora_alpha": 1,
        "target_modules": ["query_key_value"],
        "lora_dropout": 0.05,
        "bias": "lora_only",
        "task_type": "CAUSAL_LM"
    }
}